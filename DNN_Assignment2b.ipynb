{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONsa5EEhKYaSZ1lBKuFdkp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maverick98/CDS/blob/main/DNN_Assignment2b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group No 189\n",
        "\n",
        "## Group Member Names:\n",
        "• MAHESH NARAM (2023aa05876): 100%\n",
        "\n",
        "• GIRIJA SHANKAR SAHOO (023AA05235): 100%\n",
        "\n",
        "• SOURAJEET SAHOO (023aa05029): 100%\n",
        "\n",
        "• MANO RANJAN SAHU (2023aa05738): 100%"
      ],
      "metadata": {
        "id": "UABjesYJEcnP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2B: Implement the following topics demonstrated (Lab sheets) in the webinar. (4 marks)\n",
        "\n",
        "    1. Deep Neural Networks and Comparative analysis of optimizer performance\n",
        "    2. Convolutional Neural Networks (CNN)\n",
        "    3. Gated Recurrent Units (GRU)\n",
        "    4. Long Short-Term Memory (LSTM)\n"
      ],
      "metadata": {
        "id": "Cq41t0_qEB7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Deep Neural Networks (DNN)"
      ],
      "metadata": {
        "id": "iOK2R-WtEU_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSIfoZqPD7zz",
        "outputId": "6640e866-3553-4a73-aef9-8715e994b904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with Adam optimizer:\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.3904 - loss: 1.9582 - val_accuracy: 0.6550 - val_loss: 1.0574\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8053 - loss: 0.6898 - val_accuracy: 0.8250 - val_loss: 0.5445\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8879 - loss: 0.3864 - val_accuracy: 0.8750 - val_loss: 0.4050\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9480 - loss: 0.2419 - val_accuracy: 0.8800 - val_loss: 0.3535\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9561 - loss: 0.1814 - val_accuracy: 0.8900 - val_loss: 0.3468\n",
            "\n",
            "Training with SGD optimizer:\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1084 - loss: 2.2952 - val_accuracy: 0.2950 - val_loss: 2.1655\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3430 - loss: 2.0930 - val_accuracy: 0.5050 - val_loss: 2.0013\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5415 - loss: 1.9101 - val_accuracy: 0.5700 - val_loss: 1.8284\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6734 - loss: 1.7035 - val_accuracy: 0.6150 - val_loss: 1.6577\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 1.4825 - val_accuracy: 0.6800 - val_loss: 1.4838\n",
            "\n",
            "Training with RMSprop optimizer:\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4901 - loss: 1.6901 - val_accuracy: 0.7250 - val_loss: 0.9431\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8657 - loss: 0.5845 - val_accuracy: 0.7450 - val_loss: 0.7070\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8804 - loss: 0.4191 - val_accuracy: 0.7200 - val_loss: 0.7177\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9243 - loss: 0.2944 - val_accuracy: 0.9050 - val_loss: 0.3462\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9380 - loss: 0.2299 - val_accuracy: 0.9050 - val_loss: 0.3193\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load dataset and use a subset for faster training\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train[:1000] / 255.0, x_test[:200] / 255.0\n",
        "y_train, y_test = y_train[:1000], y_test[:200]\n",
        "\n",
        "# Build a simple DNN model\n",
        "def build_dnn():\n",
        "    model = models.Sequential([\n",
        "        layers.Flatten(input_shape=(28, 28)),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile and train with different optimizers\n",
        "optimizers = {'Adam': Adam(), 'SGD': SGD(), 'RMSprop': RMSprop()}\n",
        "for name, opt in optimizers.items():\n",
        "    model = build_dnn()\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    print(f\"\\nTraining with {name} optimizer:\")\n",
        "    model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Convolutional Neural Networks (CNN)"
      ],
      "metadata": {
        "id": "qSFBjCTkEi3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "# Build a simple CNN model\n",
        "def build_cnn():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Prepare the data for CNN\n",
        "x_train_cnn = x_train[..., None]\n",
        "x_test_cnn = x_test[..., None]\n",
        "\n",
        "# Use a fresh optimizer instance for each model\n",
        "optimizer_classes = {'Adam': Adam, 'SGD': SGD, 'RMSprop': RMSprop}\n",
        "\n",
        "for name, optimizer_class in optimizer_classes.items():\n",
        "    model = build_cnn()\n",
        "    opt = optimizer_class()  # Create a new instance of the optimizer\n",
        "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    print(f\"\\nTraining CNN with {name} optimizer:\")\n",
        "    model.fit(x_train_cnn, y_train, epochs=5, validation_data=(x_test_cnn, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPxuwpsaEknv",
        "outputId": "ac08bc87-701a-46ff-ce81-8192583bc40e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training CNN with Adam optimizer:\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.3230 - loss: 2.0224 - val_accuracy: 0.7800 - val_loss: 0.6956\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8140 - loss: 0.6097 - val_accuracy: 0.8800 - val_loss: 0.3411\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9016 - loss: 0.3149 - val_accuracy: 0.9250 - val_loss: 0.2998\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9346 - loss: 0.2541 - val_accuracy: 0.9250 - val_loss: 0.2495\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9443 - loss: 0.2029 - val_accuracy: 0.9600 - val_loss: 0.1426\n",
            "\n",
            "Training CNN with SGD optimizer:\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.1040 - loss: 2.3073 - val_accuracy: 0.2850 - val_loss: 2.2573\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2906 - loss: 2.2574 - val_accuracy: 0.3950 - val_loss: 2.2090\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3886 - loss: 2.1988 - val_accuracy: 0.4800 - val_loss: 2.1351\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4923 - loss: 2.1049 - val_accuracy: 0.4400 - val_loss: 2.0007\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5314 - loss: 1.9203 - val_accuracy: 0.5650 - val_loss: 1.7508\n",
            "\n",
            "Training CNN with RMSprop optimizer:\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.3891 - loss: 1.9056 - val_accuracy: 0.7000 - val_loss: 0.8390\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7806 - loss: 0.6641 - val_accuracy: 0.8100 - val_loss: 0.5261\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8795 - loss: 0.4132 - val_accuracy: 0.9150 - val_loss: 0.3177\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9185 - loss: 0.3006 - val_accuracy: 0.9200 - val_loss: 0.3293\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9513 - loss: 0.1956 - val_accuracy: 0.9250 - val_loss: 0.2632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Gated Recurrent Units (GRU)"
      ],
      "metadata": {
        "id": "EuW3cDR1EoWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Load sequential data (e.g., IMDB sentiment analysis dataset)\n",
        "max_features = 20000  # Vocabulary size\n",
        "max_len = 500  # Maximum length of sequence\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train[:1000], maxlen=max_len)\n",
        "x_test = sequence.pad_sequences(x_test[:200], maxlen=max_len)\n",
        "y_train = y_train[:1000]\n",
        "y_test = y_test[:200]\n",
        "\n",
        "# Build a GRU model\n",
        "def build_gru():\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(max_features, 128),\n",
        "        layers.GRU(128, return_sequences=False),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Use a fresh optimizer instance for each model\n",
        "optimizer_classes = {'Adam': Adam, 'SGD': SGD, 'RMSprop': RMSprop}\n",
        "\n",
        "for name, optimizer_class in optimizer_classes.items():\n",
        "    model = build_gru()\n",
        "    opt = optimizer_class()  # Create a new instance of the optimizer\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    print(f\"\\nTraining GRU with {name} optimizer:\")\n",
        "    model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npKY1V7PEpmX",
        "outputId": "c08e14b7-64af-4994-b623-3da9ba224a86"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "Training GRU with Adam optimizer:\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 756ms/step - accuracy: 0.5115 - loss: 0.6914 - val_accuracy: 0.6300 - val_loss: 0.6720\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 729ms/step - accuracy: 0.7537 - loss: 0.5866 - val_accuracy: 0.6600 - val_loss: 0.6116\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 744ms/step - accuracy: 0.9210 - loss: 0.2518 - val_accuracy: 0.6650 - val_loss: 0.6746\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 747ms/step - accuracy: 0.9638 - loss: 0.1691 - val_accuracy: 0.7300 - val_loss: 1.0005\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 748ms/step - accuracy: 0.9863 - loss: 0.0397 - val_accuracy: 0.7050 - val_loss: 1.0449\n",
            "\n",
            "Training GRU with SGD optimizer:\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 735ms/step - accuracy: 0.4669 - loss: 0.6939 - val_accuracy: 0.4350 - val_loss: 0.6942\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 721ms/step - accuracy: 0.5005 - loss: 0.6936 - val_accuracy: 0.4300 - val_loss: 0.6943\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 679ms/step - accuracy: 0.4696 - loss: 0.6940 - val_accuracy: 0.4850 - val_loss: 0.6939\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 718ms/step - accuracy: 0.5045 - loss: 0.6932 - val_accuracy: 0.4300 - val_loss: 0.6943\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 673ms/step - accuracy: 0.5117 - loss: 0.6935 - val_accuracy: 0.4350 - val_loss: 0.6942\n",
            "\n",
            "Training GRU with RMSprop optimizer:\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 710ms/step - accuracy: 0.4955 - loss: 0.6926 - val_accuracy: 0.5200 - val_loss: 0.6891\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 750ms/step - accuracy: 0.6886 - loss: 0.6692 - val_accuracy: 0.5900 - val_loss: 0.6625\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 709ms/step - accuracy: 0.7469 - loss: 0.5641 - val_accuracy: 0.6450 - val_loss: 0.6281\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 785ms/step - accuracy: 0.8602 - loss: 0.3867 - val_accuracy: 0.6950 - val_loss: 0.6383\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 722ms/step - accuracy: 0.9342 - loss: 0.2121 - val_accuracy: 0.6750 - val_loss: 0.7152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Long Short-Term Memory (LSTM)"
      ],
      "metadata": {
        "id": "jXpYFEYyEtVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "# Load IMDb dataset with fewer samples for quick training\n",
        "max_features = 20000  # Vocabulary size\n",
        "max_len = 100  # Maximum sequence length (shorter for faster training)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train[:1000], maxlen=max_len)\n",
        "x_test = sequence.pad_sequences(x_test[:200], maxlen=max_len)\n",
        "y_train = y_train[:1000]\n",
        "y_test = y_test[:200]\n",
        "\n",
        "\n",
        "\n",
        "# Build an LSTM model\n",
        "def build_lstm():\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(input_dim=max_features, output_dim=64),\n",
        "        layers.LSTM(64),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Optimizer classes\n",
        "optimizer_classes = {'Adam': Adam, 'SGD': SGD, 'RMSprop': RMSprop}\n",
        "\n",
        "for name, optimizer_class in optimizer_classes.items():\n",
        "\n",
        "\n",
        "    # Training LSTM with new optimizer instance\n",
        "    print(f\"\\nTraining LSTM with {name} optimizer:\")\n",
        "    lstm_model = build_lstm()\n",
        "    opt = optimizer_class()  # Create a new optimizer instance\n",
        "    lstm_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    lstm_model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR-M88cfEu_1",
        "outputId": "f326ea51-224e-4a0e-ae63-ceed060cff25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTM with Adam optimizer:\n",
            "Epoch 1/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - accuracy: 0.5029 - loss: 0.6922 - val_accuracy: 0.6200 - val_loss: 0.6845\n",
            "Epoch 2/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.7643 - loss: 0.6491 - val_accuracy: 0.5500 - val_loss: 0.6607\n",
            "Epoch 3/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.8116 - loss: 0.5017 - val_accuracy: 0.7150 - val_loss: 0.5570\n",
            "\n",
            "Training LSTM with SGD optimizer:\n",
            "Epoch 1/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.4683 - loss: 0.6935 - val_accuracy: 0.5150 - val_loss: 0.6929\n",
            "Epoch 2/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.5123 - loss: 0.6930 - val_accuracy: 0.5200 - val_loss: 0.6923\n",
            "Epoch 3/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.5106 - loss: 0.6930 - val_accuracy: 0.5300 - val_loss: 0.6927\n",
            "\n",
            "Training LSTM with RMSprop optimizer:\n",
            "Epoch 1/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.5137 - loss: 0.6933 - val_accuracy: 0.6150 - val_loss: 0.6892\n",
            "Epoch 2/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.6500 - loss: 0.6914 - val_accuracy: 0.6550 - val_loss: 0.6397\n",
            "Epoch 3/3\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7212 - loss: 0.5710 - val_accuracy: 0.6500 - val_loss: 0.6192\n"
          ]
        }
      ]
    }
  ]
}